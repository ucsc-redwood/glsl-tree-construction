#version 450
#extension GL_KHR_shader_subgroup_basic: enable
#extension GL_KHR_shader_subgroup_ballot: enable
#extension GL_KHR_shader_subgroup_arithmetic: enable
#extension GL_KHR_shader_subgroup_vote: enable
#extension  GL_EXT_shader_explicit_arithmetic_types_int64 : enable
#extension GL_NV_shader_atomic_int64 : enable
#extension GL_EXT_shader_subgroup_extended_types_int64 : enable
#extension GL_KHR_shader_subgroup_shuffle_relative : enable
#extension GL_KHR_shader_subgroup_shuffle : enable
#extension GL_EXT_debug_printf : require

#define input_size 131072

#define RADIX_BIN 256
#define RADIX_LOG 8
#define RADIX_BITS 8
#define RADIX_MASK 255 // Mask of digit bins
#define RADIX_PASS 4//(sizeof(uint) * 8 + RADIX_BITS - 1) / RADIX_BITS
#define SEC_RADIX           8       //Shift value to retrieve digits from the second place
#define THIRD_RADIX         16      //Shift value to retrieve digits from the third place
#define FOURTH_RADIX        24      //Shift value to retrieve digits from the fourth place 
#define SEC_RADIX_START     256     //Offset for retrieving values from global buffer
#define THIRD_RADIX_START   512     //Offset for retrieving values from global buffer
#define FOURTH_RADIX_START  768     //Offset for retrieving values from global buffer

#define LANE_COUNT 64 // number of threads in a subgroup
#define LANE_MASK 63
#define LANE_LOG 6

#define LANE gl_LocalInvocationID.x // the idx of thread in the subgroup
#define SUBGROUP_IDX  gl_LocalInvocationID.y//gl_SubgroupID // the idx of subgroup the thread belongs to might be wrong
#define SUBGROUP_THREAD_IDX gl_GlobalInvocationID.x //(LANE + (SUBGROUP_IDX << LANE_LOG)) // the subgroup relative thread idx                                 





//For the binning
#define BIN_PART_SIZE       7680    //The partition tile size of a BinningPass threadblock
#define BIN_HISTS_SIZE      4096    //The total size of all subgroup histograms in shared memory
#define BIN_TBLOCKS         2     //The number of threadblocks dispatched in a BinningPass threadblock
#define BIN_THREADS         512     //The number of threads in a BinningPass threadblock
#define BIN_SUB_PART_SIZE   960     //The subpartition tile size of a single subgroup in a BinningPass threadblock
#define BIN_SUBGROUPS       8       //The number of subgroup in a BinningPass threadblock previously 16
#define BIN_KEYS_PER_THREAD 15      //The number of keys per thread in BinningPass threadblock previously 15

#define BIN_PARTITIONS     (input_size / BIN_PART_SIZE)             //The number of partition tiles in a BinningPass
#define BIN_SUB_PART_START (SUBGROUP_IDX * BIN_SUB_PART_SIZE)     //The starting offset of a subpartition tile
#define BIN_PART_START     (partitionIndex * BIN_PART_SIZE)     //The starting offset of a partition tile
#define BIN_THREAD_BLOCKS  (input_size + BIN_PART_SIZE - 1) / BIN_PART_SIZE


#define FLAG_NOT_READY      0       //Flag value inidicating neither inclusive sum, or aggregate sum of a partition tile is ready
#define FLAG_AGGREGATE      1       //Flag value indicating aggregate sum of a partition tile is ready
#define FLAG_INCLUSIVE      2       //Flag value indicating inclusive sum of a partition tile is ready
#define FLAG_MASK           3       //Mask used to retrieve flag values



layout(set = 0, binding = 0)  buffer BSortBuffer {
    uint b_sort[input_size];
};

layout(set = 0, binding = 1)  buffer BAltBuffer {
    uint b_alt[input_size];
};

layout(set = 0, binding = 2)  buffer BGlobalHist {
    uint b_globalHist[1024];
};

layout(set = 0, binding = 3) coherent buffer BIndex {
    uint b_index[4];
};

layout(set = 0, binding = 4) coherent buffer BPassHist {
    uvec4 b_passHist[BIN_THREAD_BLOCKS*256];
};



layout(local_size_x = 512) in;

shared uint s_globalHistFirst[RADIX_BIN * 2];
shared uint s_globalHistSec[RADIX_BIN * 2];
shared uint s_globalHistThird[RADIX_BIN * 2];
shared uint s_globalHistFourth[RADIX_BIN * 2];

shared uint s_subgroupHistograms[BIN_PART_SIZE];
shared uint s_localHistograms[RADIX_BIN];



uint InclusiveWarpScanCircularShift(uint val){
    for (uint i = 1; i <= (LANE_COUNT >> 1); i <<= 1){
        const uint t = subgroupShuffleUp(val, i);
        if (gl_SubgroupInvocationID >= i)
            val += t;
    }
    return subgroupShuffle(val, (gl_SubgroupInvocationID + LANE_MASK) & LANE_MASK);
}


uint ActiveExclusiveWarpScan(uint val) {
    uint result = 0;
    for (uint i = 1; i <= (LANE_COUNT >> 1); i <<= 1){
        uint t = subgroupShuffleUp(val, i);
        if (gl_SubgroupInvocationID >= i)
            val += t;
    }
    const uint t = subgroupShuffleUp(val, 1);
    return (gl_SubgroupInvocationID > 0) ? t : 0;
}

uint getLaneMaskLt() {
    uint laneId = gl_SubgroupInvocationID;
    uint mask = 0;

    // Generate the mask dynamically based on the current laneId
    // For each bit position less than laneId, set the corresponding bit in mask
    for (uint i = 0; i < laneId; ++i) {
        mask |= (1u << i);
    }

    return mask;
}


void k_DigitBinning(uint num, uint radix_shift){

    // clear shared memory
    for(uint i = gl_LocalInvocationID.x; i < BIN_HISTS_SIZE; i += gl_WorkGroupSize.x){
        s_subgroupHistograms[i] = 0;
    }

    // assign partition tiles
    if (gl_LocalInvocationID.x == 0)
        s_subgroupHistograms[BIN_PART_SIZE - 1] = atomicAdd(b_index[radix_shift >> 3], 1);
    groupMemoryBarrier();
    barrier();

    const uint partitionIndex = s_subgroupHistograms[BIN_PART_SIZE - 1];

    // load global histogram into shared memory
    if (gl_LocalInvocationID.x < RADIX_BIN)
        s_localHistograms[gl_LocalInvocationID.x] = b_globalHist[gl_LocalInvocationID.x + (radix_shift << 5)];
    

    // handle size that is not prect multiple of parition size
    if (partitionIndex < gl_NumWorkGroups.x -1){
        // load the keys
        uint keys[BIN_KEYS_PER_THREAD];
        for (uint i = 0, t = gl_SubgroupInvocationID + BIN_SUB_PART_START + BIN_PART_START; i < BIN_KEYS_PER_THREAD; i++, t += LANE_COUNT){
            keys[i] = num % 2 == 0 ? b_sort[t] : b_alt[t];
        }

        uint _offsets[BIN_KEYS_PER_THREAD];
        

        // warp level mutli-split
        for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i){
            uint64_t warpFlags = 0xFFFFFFFFFFFFFFFFL;
            for (int k = int(radix_shift); k < radix_shift + RADIX_LOG; ++k){
                const bool t2 = ((keys[i] >> k) & 1) > 0;
                warpFlags &= (t2 ? 0 : 0xFFFFFFFFFFFFFFFFL) ^ subgroupBallot(t2).x;
            }

            // Number of peers having same digit as key[i]
            // maybe it is wrong?
            const uint bits = uint(bitCount(warpFlags & getLaneMaskLt()));

            uint prev;
            if (bits == 0)
                prev = atomicAdd(s_subgroupHistograms[(SUBGROUP_IDX << RADIX_LOG) + (keys[i] >> radix_shift & RADIX_MASK)], int(bitCount(warpFlags)));
            int shuffleIndex = int(findLSB(warpFlags));
            if (shuffleIndex != -1)
                _offsets[i] = subgroupShuffle(prev, shuffleIndex) + bits;
        }
        groupMemoryBarrier();
        barrier();

        // exclusive prefix scan up the  warp histograms
        if (gl_LocalInvocationID.x < RADIX_BIN){
            uint reduction = s_subgroupHistograms[gl_LocalInvocationID.x];
            for (uint i = gl_LocalInvocationID.x +  RADIX_BIN; i < BIN_HISTS_SIZE; i += RADIX_BIN){
                reduction += s_subgroupHistograms[i];
                s_subgroupHistograms[i] = reduction - s_subgroupHistograms[i];
            }
            uint val = ((partitionIndex != 0) ? FLAG_AGGREGATE : FLAG_INCLUSIVE) | reduction << 2;
            atomicAdd(b_passHist[gl_LocalInvocationID.x* gl_NumWorkGroups.x + partitionIndex][num], val);

            // exclusive prefix sum across reduction
            s_subgroupHistograms[gl_LocalInvocationID.x] = InclusiveWarpScanCircularShift(reduction);
        }

        groupMemoryBarrier();
        barrier();

        if (gl_LocalInvocationID.x < (RADIX_BIN >> LANE_LOG))
            s_subgroupHistograms[gl_LocalInvocationID.x << LANE_LOG] = ActiveExclusiveWarpScan(s_subgroupHistograms[gl_LocalInvocationID.x << LANE_LOG]);
        groupMemoryBarrier();
        barrier();

        // update offsets
        if (gl_SubgroupID > 0){
            for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i){
                const uint t2 = keys[i] >> radix_shift & RADIX_MASK;
                _offsets[i] += s_subgroupHistograms[(SUBGROUP_IDX << RADIX_LOG) + t2] + s_subgroupHistograms[t2]; 
            }
        }else{
            for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i){
                _offsets[i] += s_subgroupHistograms[keys[i] >> radix_shift & RADIX_MASK];
            }
        }

        // split the warps into single thread cooperative groups and lookback

        if (partitionIndex > 0){
            for (uint i = gl_LocalInvocationID.x; i < RADIX_BIN; i += gl_WorkGroupSize.x){
                uint reduction = 0;
                for( uint k = partitionIndex; k > 0;){
                    const uint flagPayload = b_passHist[i * gl_NumWorkGroups.x + k - 1][num];
                    if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE){
                        reduction += flagPayload >> 2;
                        atomicAdd(b_passHist[i * gl_NumWorkGroups.x + partitionIndex][num], 1 | (reduction << 2));
                        s_localHistograms[i] += reduction - s_subgroupHistograms[i];
                        break;
                    }

                    if ((flagPayload & FLAG_MASK) == FLAG_AGGREGATE){
                        reduction += flagPayload >> 2;
                        k--;
                    }
                }
            }
        }else{
            if (gl_LocalInvocationID.x < RADIX_BIN){
                s_localHistograms[gl_LocalInvocationID.x] -= s_subgroupHistograms[gl_LocalInvocationID.x];
            }
        }
        groupMemoryBarrier();
        barrier();

        //scatter keys into shared memory
        for (uint i = 0; i < BIN_KEYS_PER_THREAD; ++i){
            s_subgroupHistograms[_offsets[i]] = keys[i];
        }
        groupMemoryBarrier();
        barrier();

        // scatter keys into device memory
        for (uint i = gl_LocalInvocationID.x; i < BIN_PART_SIZE; i += gl_WorkGroupSize.x){
            num % 2 == 0? b_alt[s_localHistograms[s_subgroupHistograms[i] >> radix_shift & RADIX_MASK] + i] = s_subgroupHistograms[i] : b_sort[s_localHistograms[s_subgroupHistograms[i] >> radix_shift & RADIX_MASK] + i] = s_subgroupHistograms[i];
        }
    }


    // process final partition
    if (partitionIndex == gl_NumWorkGroups.x - 1){
        groupMemoryBarrier();
        barrier();

        // look back
        if (partitionIndex > 0){
            for (uint i = gl_LocalInvocationID.x; i < RADIX_BIN; i += gl_WorkGroupSize.x){
                uint reduction = 0;
                for (uint k = partitionIndex; k > 0;){
                    const uint flagPayload = b_passHist[i * gl_NumWorkGroups.x + k - 1][num];
                    if ((flagPayload & FLAG_MASK) == FLAG_INCLUSIVE){
                        reduction += flagPayload >> 2;
                        s_localHistograms[i] += reduction;
                        break;
                    }

                    if ((flagPayload & FLAG_MASK) == FLAG_AGGREGATE){
                        reduction += flagPayload >> 2;
                        k--;
                    }
                }
            }
            groupMemoryBarrier();
            barrier();
        }

        const uint partEnd = BIN_PART_START + BIN_PART_SIZE;
        for (uint i = gl_LocalInvocationID.x + BIN_PART_START; i < partEnd; i += gl_WorkGroupSize.x){
            uint key;
            uint offset;
            uint64_t warpFlags = 0xFFFFFFFFFFFFFFFFL;

            if ( i < input_size)
                key = num % 2 == 0 ? b_sort[i] : b_alt[i];
            
            for (uint k = radix_shift; k < radix_shift + RADIX_LOG; ++k){
                const bool t = (key >> k & 1) > 0;
                warpFlags &= (t ? 0 : 0xFFFFFFFFFFFFFFFFL) ^ subgroupBallot(t).x;
            }

            const uint bits = uint(bitCount(warpFlags & getLaneMaskLt()));

            for (uint k = 0; k < BIN_SUBGROUPS; ++k){
                uint prev;
                if (gl_SubgroupID.x == k && bits == 0 && i < input_size){
                    prev = atomicAdd(s_localHistograms[key >> radix_shift & RADIX_MASK], int(bitCount(warpFlags)));
                }
                if (gl_SubgroupID.x == k){
                    int shuffleIndex = int(findLSB(warpFlags));
                    offset = subgroupShuffle(prev, shuffleIndex) + bits;
                }
                groupMemoryBarrier();
                barrier();
            }

            if (i < input_size)
                num % 2 == 0 ? b_alt[offset] = key : b_sort[offset] = key;
        }
    }
}

void Init(){
    for (int i = 0; i < BIN_THREAD_BLOCKS; i++){
        b_passHist[i] = uvec4(0);
    }
    for (int i = 0; i < input_size; i++){
        b_alt[i] = 0;
    }

    for (int i = 0; i < 4; i++){
        b_index[i] = 0;
    }
}

void main(){
    Init();
    groupMemoryBarrier();
    barrier();
    k_DigitBinning(0, 0);
    groupMemoryBarrier();
    barrier();
    k_DigitBinning(1, 8);
    groupMemoryBarrier();
    barrier();
    k_DigitBinning(2, 16);
    groupMemoryBarrier();
    barrier();
    k_DigitBinning(3, 24);
    groupMemoryBarrier();
    barrier();
    
}